{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a734623",
   "metadata": {},
   "source": [
    "# Question3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff733bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Load the diabetes data (assuming you have the dataset in an excel file)\n",
    "diabetes_data = pd.read_excel(\"Diabetes_Data.xlsx\")\n",
    "\n",
    "# Extract the explanatory variables (features) from the dataset\n",
    "explanatory_variables = diabetes_data.iloc[:, :-1]\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = explanatory_variables.corr()\n",
    "\n",
    "# print correlation_matrix\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ccdd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap of the correlation matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title(\"Correlation Heatmap of Explanatory Variables\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f94dd",
   "metadata": {},
   "source": [
    "# Relationships between Variables\n",
    "\n",
    "The heatmap will visually represent the correlations between explanatory variables. Positive correlations are indicated by warmer colors (red), while negative correlations are shown in cooler colors (blue). A correlation close to 1 or -1 indicates a strong linear relationship between variables, while a correlation near 0 suggests a weak or no relationship. Analyzing the heatmap helps to identify which variables are strongly correlated with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849b4878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a linear model using Scikit-Learn\n",
    "X = explanatory_variables\n",
    "y = diabetes_data['Y']\n",
    "model1 = LinearRegression().fit(X, y)\n",
    "y_pred = model1.predict(X)\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "\n",
    "# Calculate adjusted R-squared using statsmodels\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X).fit()\n",
    "adj_r2 = model.rsquared_adj\n",
    "\n",
    "# Check significance of variables\n",
    "print(\"Adjusted R2: \", adj_r2)\n",
    "print(\"\\nMean Squared Error: \", mse)\n",
    "print()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffea98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "# define SequentialFeatureSelector\n",
    "linear = LinearRegression()\n",
    "selection_feature = SequentialFeatureSelector(linear, k_features='best', forward=True, scoring='neg_mean_squared_error')\n",
    "selection_feature.fit(X, y)\n",
    "selection_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123d2663",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_feature = list(X.columns[list(selection_feature.k_feature_idx_)])\n",
    "print(significant_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a1d505",
   "metadata": {},
   "source": [
    "# Build model2 with only significant estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f638735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a linear model using Scikit-Learn\n",
    "significant_feature = diabetes_data.iloc[:, 1:-2]\n",
    "\n",
    "X = significant_feature\n",
    "y = diabetes_data['Y']\n",
    "model2 = LinearRegression().fit(X, y)\n",
    "y_pred = model2.predict(X)\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "model2 = sm.OLS(y, X).fit()\n",
    "adj_r2 = model2.rsquared_adj\n",
    "\n",
    "print(\"Adjusted R2: \", adj_r2)\n",
    "print(\"\\nMean Squared Error: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a22217",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b58db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Titanic dataset\n",
    "titanic_data = pd.read_csv(\"titanic3.csv\")\n",
    "\n",
    "# Calculate the probability of survival\n",
    "survival_probability = titanic_data['survived'].mean()\n",
    "print(\"Probability of Survival:\", survival_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e17cbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the age interval\n",
    "age_interval = [0, 18, 80]\n",
    "label = ['0-18', '19-80']\n",
    "titanic_data['Age_Group'] = pd.cut(titanic_data['age'], bins=age_interval, labels=label)\n",
    "\n",
    "#group data by passenger class, gender, and age, and calculate the mean survival for each group\n",
    "survival_table = titanic_data.groupby([\"pclass\", \"sex\", \"Age_Group\"])[\"survived\"].mean()\n",
    "\n",
    "#display the table\n",
    "print(survival_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc12acd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the data\n",
    "X = titanic_data[[\"pclass\", \"sex\", \"age\"]].copy()\n",
    "y = titanic_data[\"survived\"]\n",
    "\n",
    "# encode categorical variables (sex) as binary\n",
    "X[\"sex\"] = X[\"sex\"].map({\"female\": 0, \"male\": 1})\n",
    "\n",
    "# Handle missing values in the age column by filling with the mean\n",
    "X[\"age\"].fillna(X[\"age\"].mean(), inplace=True)\n",
    "\n",
    "# Split the data into a training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# remove the outliers\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test= scaler.transform(X_test)\n",
    "\n",
    "# Build and fit the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Print the model coefficients (parameter estimates)\n",
    "coefficients = model.coef_\n",
    "intercept = model.intercept_\n",
    "print(\"Model Coefficients (Parameters):\")\n",
    "print(\"Intercept (Bias):\", intercept)\n",
    "print(\"Coefficient for pclass:\", coefficients[0, 0])\n",
    "print(\"Coefficient for sex:\", coefficients[0, 1])\n",
    "print(\"Coefficient for age:\", coefficients[0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf59264a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard errors of coefficients\n",
    "coef_standard_errors = np.sqrt(np.diag(np.linalg.inv(np.dot(X_train.T, X_train))))\n",
    "\n",
    "# Calculate Wald statistics for each coefficient\n",
    "wald_stats = model.coef_ / coef_standard_errors\n",
    "\n",
    "# Calculate two-tailed p-values for each coefficient\n",
    "p_values = 2 * (1 - stats.norm.cdf(np.abs(wald_stats)))\n",
    "\n",
    "# Define a significance level (e.g., 0.05)\n",
    "alpha = 0.05\n",
    "\n",
    "# Determine the number of variables\n",
    "num_variables = len(p_values[0])\n",
    "\n",
    "# Check which coefficients are statistically significant\n",
    "significant_variables = []\n",
    "for i in range(num_variables):\n",
    "    if p_values[0, i] < alpha:\n",
    "        significant_variables.append(\"Yes\")\n",
    "    else:\n",
    "        significant_variables.append(\"No\")\n",
    "\n",
    "# Print the results\n",
    "print(\"Wald Statistics:\")\n",
    "for i in range(num_variables):\n",
    "    print(f\"Coefficient for {X.columns[i]}:\", wald_stats[0, i])\n",
    "\n",
    "print(\"\\nP-values:\")\n",
    "for i in range(num_variables):\n",
    "    print(f\"P-value for {X.columns[i]}:\", p_values[0, i])\n",
    "\n",
    "print(\"\\nStatistically Significant Variables:\")\n",
    "for i in range(num_variables):\n",
    "    print(f\"Is {X.columns[i]} significant?\", significant_variables[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa015c1",
   "metadata": {},
   "source": [
    "# performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe7270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calculate classification metrics\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (conf_matrix[0, 0] + conf_matrix[1, 1]) / np.sum(conf_matrix)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Display classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
